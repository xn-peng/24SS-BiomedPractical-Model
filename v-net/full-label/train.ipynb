{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4af0235-4e2f-45f5-8ce3-db76683b23d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the dataloader: 388\n",
      "Total dataset size: 388\n",
      "Training set size: 271\n",
      "Validation set size: 58\n",
      "Test set size: 59\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import nibabel as nib\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'\n",
    "\n",
    "directory = '../../../Aims-Tbi'\n",
    "demographics_file = '../../TestSet_demographics.xlsx'\n",
    "\n",
    "class MRIDataset(Dataset):\n",
    "    def __init__(self, directory, demographics_file, transform=None):\n",
    "        self.directory = directory\n",
    "        self.transform = transform\n",
    "\n",
    "        self.demographics = pd.read_excel(demographics_file)\n",
    "\n",
    "        self.demographics['ScanManufacturer'] = pd.Categorical(self.demographics['ScanManufacturer']).codes\n",
    "        self.demographics['Sex'] = self.demographics['Sex'].astype(float)\n",
    "\n",
    "        self.mri_paths = []\n",
    "        self.labels_paths = []\n",
    "        self.diag_data = []\n",
    "\n",
    "        available_mris = set(f.replace('_T1.nii.gz', '') for f in os.listdir(directory) if f.endswith('_T1.nii.gz'))\n",
    "\n",
    "        for _, row in self.demographics.iterrows():\n",
    "            rand_id = row['RandID']\n",
    "            if rand_id in available_mris:\n",
    "                mri_file = os.path.join(directory, f\"{rand_id}_T1.nii.gz\")\n",
    "                label_file = os.path.join(directory, f\"{rand_id}_Lesion.nii.gz\")\n",
    "                if os.path.exists(mri_file) and os.path.exists(label_file):\n",
    "                    self.mri_paths.append(mri_file)\n",
    "                    self.labels_paths.append(label_file)\n",
    "                    self.diag_data.append(row)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mri_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        mri_path = self.mri_paths[idx]\n",
    "        label_path = self.labels_paths[idx]\n",
    "        diag_row = self.diag_data[idx]\n",
    "\n",
    "        mri_img = nib.load(mri_path).get_fdata()\n",
    "        label_img = nib.load(label_path).get_fdata()\n",
    "\n",
    "        mri_tensor = torch.tensor(mri_img, dtype=torch.float32).unsqueeze(0)  # 添加一个通道维度\n",
    "        label_tensor = torch.tensor(label_img, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "        diag_values = [float(diag_row['Age']), diag_row['Sex'], float(diag_row['TSI']), diag_row['ScanManufacturer']]\n",
    "        diag_tensor = torch.tensor(diag_values, dtype=torch.float32)\n",
    "\n",
    "        if self.transform:\n",
    "            mri_tensor = self.transform(mri_tensor)\n",
    "            label_tensor = self.transform(label_tensor)\n",
    "\n",
    "        return mri_tensor, label_tensor, diag_tensor\n",
    "\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256)  # Adjust size if necessary\n",
    "])\n",
    "dataset = MRIDataset(directory=directory, demographics_file=demographics_file, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "print(\"The length of the dataloader:\", len(dataloader));\n",
    "\n",
    "\n",
    "total_size = len(dataset)\n",
    "print(f\"Total dataset size: {total_size}\")\n",
    "\n",
    "train_size = int(total_size * 0.70)\n",
    "val_size = int(total_size * 0.15)\n",
    "test_size = total_size - train_size - val_size  # 保证所有样本都被使用\n",
    "\n",
    "if val_size == 0 or test_size == 0:\n",
    "    raise ValueError(\"Dataset too small to split according to the specified ratios. Increase dataset size or adjust the ratios.\")\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "print(f\"Training set size: {len(train_loader)}\")\n",
    "print(f\"Validation set size: {len(val_loader)}\")\n",
    "print(f\"Test set size: {len(test_loader)}\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "weights_dir = 'weights'\n",
    "os.makedirs(weights_dir, exist_ok=True)\n",
    "\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=20):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        progress_bar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        for i, (mri, labels, diag) in progress_bar:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            mri, labels, diag = mri.to(device), labels.to(device), diag.to(device)\n",
    "            \n",
    "            labels = torch.sigmoid(labels) \n",
    "            \n",
    "            outputs = model(mri, diag)\n",
    "            outputs = torch.sigmoid(outputs)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            progress_bar.set_postfix(loss=running_loss / (i + 1))\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n",
    "        torch.save(model.state_dict(), os.path.join(weights_dir, f'model_epoch_{epoch+1}.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f35394-fe67-4097-b54d-d6f81dcd0847",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vnet import VNetWithDiagnosis\n",
    "\n",
    "model = VNetWithDiagnosis().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.BCELoss()\n",
    "scaler = GradScaler()\n",
    "\n",
    "train_model(model, train_loader, criterion, optimizer)\n",
    "\n",
    "torch.save(model.state_dict(), 'trained_vnet.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
